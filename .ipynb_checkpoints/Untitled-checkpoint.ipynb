{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Craig/eclipse-workspace/test_keras/chorales_generation/data/chorales.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ebf59b618c86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_preprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess_notes_as_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_preprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_is_nan\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mchorales_generation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_preprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mchorale_intro\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\SharpestMinds-Application\\chorales_generation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mkeysig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Get the preprocessed data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_notes_as_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeysig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeysig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;31m# Convert the dataframe into an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mdata_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\SharpestMinds-Application\\data_preprocessing.py\u001b[0m in \u001b[0;36mpreprocess_notes_as_array\u001b[1;34m(keysig)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# Read the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     data = pd.read_table('C:/Users/Craig/eclipse-workspace/test_keras/chorales_generation/data/chorales.csv',\n\u001b[1;32m---> 63\u001b[1;33m                          sep=',', names=usecols, engine='python', header=None)\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[1;31m# Remove the first column and every other column which contain attribute names.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;31m# The first column is an unneeded index column.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    993\u001b[0m                                  ' \"c\", \"python\", or' ' \"python-fwf\")'.format(\n\u001b[0;32m    994\u001b[0m                                      engine=engine))\n\u001b[1;32m--> 995\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_keras\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, **kwds)\u001b[0m\n\u001b[0;32m   1983\u001b[0m         f, handles = _get_handle(f, mode, encoding=self.encoding,\n\u001b[0;32m   1984\u001b[0m                                  \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1985\u001b[1;33m                                  memory_map=self.memory_map)\n\u001b[0m\u001b[0;32m   1986\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_keras\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Craig/eclipse-workspace/test_keras/chorales_generation/data/chorales.csv'"
     ]
    }
   ],
   "source": [
    "''' A place to load a model and feed it different initial phrases to see what the model does! '''\n",
    "from data_preprocessing import preprocess_notes_as_array\n",
    "from data_preprocessing import array_is_nan\n",
    "from chorales_generation import sample\n",
    "from data_preprocessing import chorale_intro\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import load_model\n",
    "from ast import literal_eval\n",
    "\n",
    "# Get the preprocessed data\n",
    "df = preprocess_notes_as_array(keysig = True)\n",
    "# Convert the dataframe into an array\n",
    "data_array = df.values\n",
    "# Reshape the data into a single array\n",
    "data_array = data_array.reshape(1,data_array.size)[0]\n",
    "# Identify all of the (nan, nan) entries\n",
    "index = np.argwhere(array_is_nan(data_array))\n",
    "# Convert the corpus into a list and delete the (nan,nan) entries\n",
    "corpus = np.ndarray.tolist(np.delete(data_array, index))\n",
    "\n",
    "print('corpus length:', len(corpus))\n",
    "\n",
    "\n",
    "notes = sorted(list(set(corpus)))\n",
    "print('total notes:', len(notes))\n",
    "note_indices = dict((n, i) for i, n in enumerate(notes))\n",
    "indices_note = dict((i, n) for i, n in enumerate(notes))\n",
    "\n",
    "\n",
    "\n",
    "filename = 'models/chorales_generation_model_maxlen-10.h5'\n",
    "# Load the model\n",
    "model = load_model(filename)\n",
    "# The maxlen variable on that was used to train the model\n",
    "maxlen = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play_chorale(phrase, diversity)\n",
    "\n",
    "    #for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = []\n",
    "        generated = generated + phrase\n",
    "        print('----- Generating with seed: \"{}\"'.format(phrase))\n",
    "        \n",
    "        print('Generated: {}'.format(generated))\n",
    "        \n",
    "        for i in range(40):\n",
    "            z = np.zeros((1, maxlen, len(notes)))\n",
    "            for t, note in enumerate(phrase):\n",
    "                z[0, t, note_indices[note]] = 1.\n",
    "\n",
    "            preds = model.predict(z, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_note = indices_note[next_index]\n",
    "            \n",
    "            generated = generated + [next_note]\n",
    "    \n",
    "            phrase.append(next_note)\n",
    "            phrase = phrase[1:]\n",
    "            \n",
    "        file = open('outputs/texts/chorale_playground_diversity-{}.txt'.format(diversity), 'w')\n",
    "        try:\n",
    "            for note in generated:\n",
    "                file.write('{}\\n'.format(note))\n",
    "        finally:\n",
    "            file.close()\n",
    "\n",
    "    from chorale_player import write_chorale\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        file = open('outputs/texts/chorale_playground_diversity-{}.txt'.format(diversity), 'r')\n",
    "        z = file.readlines()\n",
    "    # print(z)\n",
    "        chorale = [x.strip('\\n') for x in z] \n",
    "     \n",
    "        chorale = [literal_eval(x) for x in chorale]\n",
    "    \n",
    "        track_name = write_chorale(chorale, track_title = \"test_name\", extra_last_note = True)\n",
    "    \n",
    "        from chorale_player import play_chorale_midi\n",
    "    \n",
    "        play_chorale_midi(track_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a variable a phrase of notes of the form [(midi pitch, duration in 16th notes), (midi pitch, duration in 16th notes), ... ]\n",
    "# consisting of 10 notes\n",
    "# For example,\n",
    "# phrase = [(64, 4, 1), (67, 4, 1), (67, 4, 1), (69, 4, 1), (69, 4, 1), \n",
    "#             (71, 4, 1), (71, 4, 1), (71, 4, 1), (74, 4, 1), (72, 4, 1)]\n",
    "# Or, use the function chorale_intro to take the first maxlen notes from chorale num_chorale.\n",
    "# For example, \n",
    "# num_chorale = 5\n",
    "# phrase = chorale_intro(num_notes = maxlen, num_chorale = num_chorale, keysig = True)\n",
    "# phrase = np.ndarray.tolist(phrase)\n",
    "\n",
    "num_chorale = 10\n",
    "phrase = chorale_intro(num_notes = maxlen, num_chorale = num_chorale, keysig = True)\n",
    "phrase = np.ndarray.tolist(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the function play_chorale(phrase, diversity) where the phrase is as above, and diversity of a positive number \n",
    "# indicating how `interesting' the generated chorale should be. A higher number will take more chances, while a lower number \n",
    "# may be fairly monotone. Try diversity = 0.5 to start.\n",
    "# For example, play_chorale(phrase, 0.5)\n",
    "\n",
    "play_chorale(phrase, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
